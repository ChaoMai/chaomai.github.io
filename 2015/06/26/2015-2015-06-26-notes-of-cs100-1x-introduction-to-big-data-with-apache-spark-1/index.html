<!doctype html>




<html class="theme-next mist">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"/>




  <link href="//fonts.googleapis.com/css?family=Lato:300,400,700,400italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">



<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=0.5.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="spark,pyspark,edx," />





  <link rel="alternate" href="/atom.xml" title="Building Things" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=0.5.0" />






<meta name="description" content="Notes of Lecture 3 Big Data, Hardware Trends, and Apache Spark.">
<meta property="og:type" content="article">
<meta property="og:title" content="Notes of CS100.1x Introduction to Big Data With Apache Spark (1)">
<meta property="og:url" content="http://chaomai.github.io/2015/06/26/2015-2015-06-26-notes-of-cs100-1x-introduction-to-big-data-with-apache-spark-1/index.html">
<meta property="og:site_name" content="Building Things">
<meta property="og:description" content="Notes of Lecture 3 Big Data, Hardware Trends, and Apache Spark.">
<meta property="og:image" content="http://spark-mooc.github.io/web-assets/images/executors.png">
<meta property="og:image" content="http://spark-mooc.github.io/web-assets/images/partitions.png">
<meta property="og:image" content="http://spark-mooc.github.io/web-assets/images/map.png">
<meta property="og:image" content="http://spark-mooc.github.io/web-assets/images/reduce_by.png">
<meta property="og:image" content="http://spark-mooc.github.io/web-assets/images/group_by.png">
<meta property="og:updated_time" content="2015-09-25T11:07:39.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Notes of CS100.1x Introduction to Big Data With Apache Spark (1)">
<meta name="twitter:description" content="Notes of Lecture 3 Big Data, Hardware Trends, and Apache Spark.">
<meta name="twitter:image" content="http://spark-mooc.github.io/web-assets/images/executors.png">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: false,
    duoshuo: {
      userId: 0,
      author: 'Author'
    }
  };
</script>

  <title> Notes of CS100.1x Introduction to Big Data With Apache Spark (1) | Building Things </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Building Things</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">Just want to know how it works!</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-home fa-fw"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-user fa-fw"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-archive fa-fw"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-tags fa-fw"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Notes of CS100.1x Introduction to Big Data With Apache Spark (1)
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2015-06-26T17:15:43+08:00" content="2015-06-26">
              2015-06-26
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2015/06/26/2015-2015-06-26-notes-of-cs100-1x-introduction-to-big-data-with-apache-spark-1/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2015/06/26/2015-2015-06-26-notes-of-cs100-1x-introduction-to-big-data-with-apache-spark-1/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="Lecture-3-Big-Data-Hardware-Trends-and-Apache-Spark-and-Lecture-4-Spark-Essentials"><a href="#Lecture-3-Big-Data-Hardware-Trends-and-Apache-Spark-and-Lecture-4-Spark-Essentials" class="headerlink" title="Lecture 3: Big Data, Hardware Trends, and Apache Spark and Lecture 4: Spark Essentials"></a>Lecture 3: Big Data, Hardware Trends, and Apache Spark and Lecture 4: Spark Essentials</h2><h3 id="The-Big-Data-Problem"><a href="#The-Big-Data-Problem" class="headerlink" title="The Big Data Problem"></a>The Big Data Problem</h3><ul>
<li>Growing data sources</li>
<li>Storage getting cheapper</li>
<li>But stalling CPU and storage bottlenecks</li>
</ul>
<h3 id="Hardware-for-Big-Data"><a href="#Hardware-for-Big-Data" class="headerlink" title="Hardware for Big Data"></a>Hardware for Big Data</h3><p>Problems with cheap hardware</p>
<ul>
<li>Failures</li>
<li>Network</li>
<li>Uneven performance</li>
</ul>
<h3 id="What’s-Hard-About-Cluster-Computing"><a href="#What’s-Hard-About-Cluster-Computing" class="headerlink" title="What’s Hard About Cluster Computing"></a>What’s Hard About Cluster Computing</h3><ul>
<li>Divide work across machines<ul>
<li>Must consider network, data locality</li>
<li>Moving data may be veay expensive</li>
</ul>
</li>
<li>Deal with failures</li>
</ul>
<h2 id="Spark-Essentials"><a href="#Spark-Essentials" class="headerlink" title="Spark Essentials"></a>Spark Essentials</h2><h3 id="PySpark"><a href="#PySpark" class="headerlink" title="PySpark"></a>PySpark</h3><p>A Spark program consists of two programs, a driver program<br>and a workers program.</p>
<ul>
<li>Drivers program: runs on the driver machine.</li>
<li>Worker programs: run on cluster nodes<br>or in local threads.</li>
</ul>
<p>RDDs are distributed across the workers.</p>
<h3 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h3><p>An RDD is immutable, so once it is created, it cannot be changed.</p>
<p>types of operations:</p>
<ul>
<li><p>transformations</p>
<ul>
<li>lazily evaluated.</li>
<li>A transformed RDD is executed only when an action runs on it.</li>
<li>can also persist, or cache RDDs in memory or on disk.<br>?</li>
</ul>
</li>
<li><p>actions</p>
<ul>
<li>cause Spark to execute the recipe to transform the source data.</li>
</ul>
</li>
</ul>
<h3 id="Spark-Programming-Model"><a href="#Spark-Programming-Model" class="headerlink" title="Spark Programming Model"></a>Spark Programming Model</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lines = sc.textFile(<span class="string">"..."</span>, <span class="number">4</span>)</span><br><span class="line">comments = lines.filter(isComment)</span><br><span class="line"><span class="keyword">print</span> lines.count(), comments.count()</span><br></pre></td></tr></table></figure>
<p><code>comments.count()</code> is going to cause Spark to re-compute lines. reread all of the data from that text file again, sum within the partition the number of lines, so the number of elements, and then combine those sums in the driver.</p>
<h3 id="Caching-RDDS"><a href="#Caching-RDDS" class="headerlink" title="Caching RDDS"></a>Caching RDDS</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lines = sc.textFile(<span class="string">"..."</span>, <span class="number">4</span>)</span><br><span class="line">lines.cache()</span><br><span class="line">comments = lines.filter(isComment)</span><br><span class="line"><span class="keyword">print</span> lines.count(), comments.count()</span><br></pre></td></tr></table></figure>
<p>create the comments RDD directly, instead of reading from disk.</p>
<h3 id="Spark-Program-Lifecycle"><a href="#Spark-Program-Lifecycle" class="headerlink" title="Spark Program Lifecycle"></a>Spark Program Lifecycle</h3><ol>
<li>create RDDs from some external data source or parallelize a collection in your driver program.</li>
<li>lazily transform these RDDs into new RDDs.</li>
<li>cache some of those RDDs for future reuse.</li>
<li>perform actions to execute parallel computation and to produce results.</li>
</ol>
<h3 id="Spark-Broadcast-Variables"><a href="#Spark-Broadcast-Variables" class="headerlink" title="Spark Broadcast Variables"></a>Spark Broadcast Variables</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">broadcast_var = sc.broadcast([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">...</span><br><span class="line">broadcast_var.value</span><br></pre></td></tr></table></figure>
<p>Keep a read-only variable cached at a worker and will be reused every time we need to access it instead of constructing another closure.</p>
<h3 id="Spark-Accumulators"><a href="#Spark-Accumulators" class="headerlink" title="Spark Accumulators"></a>Spark Accumulators</h3><p>could only be added to by an associative operation. They’re used to very efficiently implement parallel counters and sums, and only the driver can read an accumulator’s values, not the tasks.</p>
<p>can be used in actions or transformations:</p>
<ul>
<li>actions: each tasks update to the accumulator is guaranteed by spark to <strong>only be applied once</strong>.</li>
<li>transformations: no guarantee.</li>
</ul>
<p>support the types:</p>
<ul>
<li>integers</li>
<li>double</li>
<li>long</li>
<li>float</li>
<li>custom types</li>
</ul>
<h2 id="About-pySpark"><a href="#About-pySpark" class="headerlink" title="About pySpark"></a>About pySpark</h2><h3 id="Spark-Context"><a href="#Spark-Context" class="headerlink" title="Spark Context"></a>Spark Context</h3><p>When running Spark, you start a new Spark application by creating a SparkContext. When the SparkContext is created, it asks the master for some cores to use to do work. The master sets these cores aside just for you; they <strong>won’t be used for other applications</strong>.</p>
<p>Driver programs access Spark through a SparkContext object, which represents <strong>a connection to a computing cluster</strong>. A Spark context object (sc) is the main entry point for Spark functionality. A Spark context can be used to create Resilient Distributed Datasets (RDDs) on a cluster.</p>
<p><img src="http://spark-mooc.github.io/web-assets/images/executors.png" alt=""></p>
<h3 id="Resilient-Distributed-Datasets-RDDs"><a href="#Resilient-Distributed-Datasets-RDDs" class="headerlink" title="Resilient Distributed Datasets (RDDs)"></a>Resilient Distributed Datasets (RDDs)</h3><p><img src="http://spark-mooc.github.io/web-assets/images/partitions.png" alt=""></p>
<h3 id="map"><a href="#map" class="headerlink" title="map()"></a><code>map()</code></h3><p>When you run <code>map()</code> on a dataset, a <strong>single stage of tasks</strong> is launched. A stage is <em>a group of tasks that all perform the same computation, but on different input data</em>. <strong>One task is launched for each partition</strong>. A task is <em>a unit of execution that runs on a single machine</em>. When we run <code>map(f)</code> within a partition, a new task applies f to all of the entries in a particular partition, and outputs a new partition.</p>
<p><img src="http://spark-mooc.github.io/web-assets/images/map.png" alt=""></p>
<p>When applying the <code>map()</code> transformation, each item in the parent RDD will map to one element in the new RDD.</p>
<h3 id="collect"><a href="#collect" class="headerlink" title="collect()"></a><code>collect()</code></h3><p>the data returned to the driver <strong>must fit into the driver’s available memory</strong>. If not, the driver will crash.</p>
<h3 id="first-and-take"><a href="#first-and-take" class="headerlink" title="first() and take()"></a><code>first()</code> and <code>take()</code></h3><p><code>first()</code> and <code>take()</code> actions, the elements that are returned depend on how the RDD is partitioned.</p>
<h3 id="takeOrdered"><a href="#takeOrdered" class="headerlink" title="takeOrdered()"></a><code>takeOrdered()</code></h3><p>The key advantage of using <code>takeOrdered()</code> instead of <code>first()</code> or <code>take()</code> is that <code>takeOrdered()</code> returns a <strong>deterministic result</strong>, while the other two actions may return different results, <em>depending on the number of partitions or execution environment</em>.</p>
<p><code>takeOrdered()</code> returns the list sorted in <strong>ascending order</strong>. The <code>top()</code> action is similar to <code>takeOrdered()</code> except that it returns the list in <strong>descending order</strong>.</p>
<h3 id="reduce"><a href="#reduce" class="headerlink" title="reduce()"></a><code>reduce()</code></h3><p>reduces the elements of a RDD to a single value by applying a function that takes two parameters and returns a single value.</p>
<p>The function should be <strong>commutative and associative（可交换和可结合）</strong>, as <code>reduce()</code> is applied at the partition level and then again to aggregate results from partitions.</p>
<h3 id="takeSample-and-countByValue"><a href="#takeSample-and-countByValue" class="headerlink" title="takeSample() and countByValue()"></a><code>takeSample()</code> and <code>countByValue()</code></h3><p>The <code>takeSample()</code> action returns an array with a random sample of elements from the dataset. It takes in a <code>withReplacement</code> argument, which specifies whether it is okay to randomly pick the same item multiple times from the parent RDD. It also takes an optional <code>seed</code> parameter that allows you to specify a seed value for the random number generator, so that reproducible results can be obtained.</p>
<p>The <code>countByValue()</code> action returns <strong>the count of each unique value</strong> in the RDD as a dictionary that maps values to counts.</p>
<h3 id="flatMap"><a href="#flatMap" class="headerlink" title="flatMap()"></a><code>flatMap()</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">simpleRDD = sc.parallelize([[[<span class="number">9</span>,<span class="number">9</span>,<span class="number">9</span>],<span class="number">2</span>,<span class="number">3</span>], [[<span class="number">9</span>,<span class="number">9</span>,<span class="number">9</span>],<span class="number">3</span>,<span class="number">4</span>], [[<span class="number">9</span>,<span class="number">9</span>,<span class="number">9</span>],<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line"><span class="keyword">print</span> simpleRDD.map(<span class="keyword">lambda</span> x:x).collect()</span><br><span class="line"><span class="keyword">print</span> simpleRDD.flatMap(<span class="keyword">lambda</span> x:x).collect()</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line">[[[<span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>], <span class="number">2</span>, <span class="number">3</span>], [[<span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>], <span class="number">3</span>, <span class="number">4</span>], [[<span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>], <span class="number">5</span>, <span class="number">6</span>]]</span><br><span class="line">[[<span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>], <span class="number">2</span>, <span class="number">3</span>, [<span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>], <span class="number">3</span>, <span class="number">4</span>, [<span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>], <span class="number">5</span>, <span class="number">6</span>]</span><br></pre></td></tr></table></figure>
<h3 id="groupByKey-and-reduceByKey"><a href="#groupByKey-and-reduceByKey" class="headerlink" title="groupByKey() and reduceByKey()"></a><code>groupByKey()</code> and <code>reduceByKey()</code></h3><p>Both of these transformations operate on <em>pair RDDs</em>. A pair RDD is an RDD where <em>each element is a pair tuple (key, value)</em>.</p>
<p><img src="http://spark-mooc.github.io/web-assets/images/reduce_by.png" alt=""></p>
<p><img src="http://spark-mooc.github.io/web-assets/images/group_by.png" alt=""></p>
<p><code>reduceByKey()</code> operates by applying the function first within each partition on a per-key basis and then across the partitions.</p>
<ul>
<li>the <code>reduceByKey()</code> transformation works much better for large distributed datasets. This is because Spark knows it can <em>combine output with a common key on each partition before shuffling</em> (redistributing) the data across nodes. Only use <code>groupByKey()</code> if the operation would not benefit from reducing the data before the shuffle occurs.</li>
<li>On the other hand, when using the <code>groupByKey()</code> transformation - all the key-value pairs are shuffled around, causing a lot of unnecessary data to being transferred over the network.</li>
</ul>
<h3 id="cache-and-unpersist"><a href="#cache-and-unpersist" class="headerlink" title="cache() and unpersist()"></a><code>cache()</code> and <code>unpersist()</code></h3><p>if you cache too many RDDs and Spark runs out of memory, it will delete the least recently used (LRU) RDD first. The RDD will be automatically recreated when accessed.</p>
<p>tell Spark to stop caching it in memory by using the RDD’s <code>unpersist()</code> method.</p>

      
    </div>

    <div>
      
        
      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/spark/" rel="tag">#spark</a>
          
            <a href="/tags/pyspark/" rel="tag">#pyspark</a>
          
            <a href="/tags/edx/" rel="tag">#edx</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2015/06/22/2015-2015-06-22-tmux/" rel="next" title="Tmux">
                <i class="fa fa-chevron-left"></i> Tmux
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2015/07/18/2015-2015-07-18-cpp-concurrency-in-action-5/" rel="prev" title="C++ Concurrency in Action (5) - the C++ Memory Model and Operations on Atomic Types">
                C++ Concurrency in Action (5) - the C++ Memory Model and Operations on Atomic Types <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/default_avatar.jpg"
               alt="Chao Mai" />
          <p class="site-author-name" itemprop="name">Chao Mai</p>
          <p class="site-description motion-element" itemprop="description">Chao Mai's Blog</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">54</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">9</span>
                <span class="site-state-item-name">categories</span>
              
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">26</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/ChaoMai" target="_blank">
                  
                    <i class="fa fa-globe"></i> github
                  
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/1898970107" target="_blank">
                  
                    <i class="fa fa-globe"></i> weibo
                  
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.douban.com/people/chaomai" target="_blank">
                  
                    <i class="fa fa-globe"></i> douban
                  
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://twitter.com/chao__mai" target="_blank">
                  
                    <i class="fa fa-globe"></i> twitter
                  
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.zhihu.com/people/chaomai" target="_blank">
                  
                    <i class="fa fa-globe"></i> zhihu
                  
                </a>
              </span>
            
          
        </div>

        
        
          <div class="cc-license motion-element" itemprop="license">
            <a href="http://creativecommons.org/licenses/by-nc-sa/4.0" class="cc-opacity" target="_blank">
              <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
            </a>
          </div>
        

        
        <div class="links-of-blogroll motion-element">
          
        </div>

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Lecture-3-Big-Data-Hardware-Trends-and-Apache-Spark-and-Lecture-4-Spark-Essentials"><span class="nav-number">1.</span> <span class="nav-text">Lecture 3: Big Data, Hardware Trends, and Apache Spark and Lecture 4: Spark Essentials</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#The-Big-Data-Problem"><span class="nav-number">1.1.</span> <span class="nav-text">The Big Data Problem</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hardware-for-Big-Data"><span class="nav-number">1.2.</span> <span class="nav-text">Hardware for Big Data</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#What’s-Hard-About-Cluster-Computing"><span class="nav-number">1.3.</span> <span class="nav-text">What’s Hard About Cluster Computing</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark-Essentials"><span class="nav-number">2.</span> <span class="nav-text">Spark Essentials</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#PySpark"><span class="nav-number">2.1.</span> <span class="nav-text">PySpark</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RDD"><span class="nav-number">2.2.</span> <span class="nav-text">RDD</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-Programming-Model"><span class="nav-number">2.3.</span> <span class="nav-text">Spark Programming Model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Caching-RDDS"><span class="nav-number">2.4.</span> <span class="nav-text">Caching RDDS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-Program-Lifecycle"><span class="nav-number">2.5.</span> <span class="nav-text">Spark Program Lifecycle</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-Broadcast-Variables"><span class="nav-number">2.6.</span> <span class="nav-text">Spark Broadcast Variables</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-Accumulators"><span class="nav-number">2.7.</span> <span class="nav-text">Spark Accumulators</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#About-pySpark"><span class="nav-number">3.</span> <span class="nav-text">About pySpark</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-Context"><span class="nav-number">3.1.</span> <span class="nav-text">Spark Context</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Resilient-Distributed-Datasets-RDDs"><span class="nav-number">3.2.</span> <span class="nav-text">Resilient Distributed Datasets (RDDs)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#map"><span class="nav-number">3.3.</span> <span class="nav-text">map()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#collect"><span class="nav-number">3.4.</span> <span class="nav-text">collect()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#first-and-take"><span class="nav-number">3.5.</span> <span class="nav-text">first() and take()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#takeOrdered"><span class="nav-number">3.6.</span> <span class="nav-text">takeOrdered()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#reduce"><span class="nav-number">3.7.</span> <span class="nav-text">reduce()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#takeSample-and-countByValue"><span class="nav-number">3.8.</span> <span class="nav-text">takeSample() and countByValue()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#flatMap"><span class="nav-number">3.9.</span> <span class="nav-text">flatMap()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#groupByKey-and-reduceByKey"><span class="nav-number">3.10.</span> <span class="nav-text">groupByKey() and reduceByKey()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cache-and-unpersist"><span class="nav-number">3.11.</span> <span class="nav-text">cache() and unpersist()</span></a></li></ol></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2014 - 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chao Mai</span>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="http://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>



      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  


  




<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=0.5.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=0.5.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=0.5.0"></script>
<script type="text/javascript" src="/vendors/jquery-scrollintoview/jquery.scrollintoview.min.js?v=0.5.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=0.5.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=0.5.0"></script>



  



  

    <script type="text/javascript">
      var disqus_shortname = 'chaomaisblog';
      var disqus_identifier = '2015/06/26/2015-2015-06-26-notes-of-cs100-1x-introduction-to-big-data-with-apache-spark-1/';
      var disqus_title = 'Notes of CS100.1x Introduction to Big Data With Apache Spark (1)';
      var disqus_url = 'http://chaomai.github.io/2015/06/26/2015-2015-06-26-notes-of-cs100-1x-introduction-to-big-data-with-apache-spark-1/';

      function run_disqus_script(disqus_script){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      }

      run_disqus_script('count.js');
      
        run_disqus_script('embed.js');
      
    </script>
  



  
  
  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>

  
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
